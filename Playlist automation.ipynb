{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BHT Data Applications project\n",
    "# Automatic Anime recommendation Algorithm\n",
    "### This project aims to create an algorithm that can determine what anime to recommend to a user.\n",
    "##### Authors: Rashmi Di Michino and Antonin Mathubert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 320000 users and 16000 animes dataset was taken from https://www.kaggle.com/datasets/hernan4444/anime-recommendation-database-2020 <br>\n",
    "We are going to use this dataset to build a model that can recommend an anime based on the animes that the user is watching, has dropped, has kept on hold or put on their watching list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing and parsing the data\n",
    "First, we want to import all of our available data in a suitable manner so it is treatable for the next steps of the project.<br><br>\n",
    "In order to load the data, we are going to do it by chunking the csv file so it's more efficient. Then we're changing the default type of the columns to be more convenient memory wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/rashm/OneDrive/Desktop/data_applications_project/julius/anime_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"dataset/anime/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_chunks = pd.read_csv(path+\"animelist.csv\", chunksize=20000)\n",
    "\n",
    "chunks = []\n",
    "for chunk in dataset_chunks:\n",
    "    chunks.append(chunk)\n",
    "    \n",
    "dataset = pd.concat(chunks, ignore_index=True)\n",
    "dataset = dataset.astype({'user_id': \"int32\", 'anime_id': 'int32', \"watching_status\": \"int16\"})\n",
    "\n",
    "dataset_chunks = None\n",
    "chunks = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Recommendation system based on the watched animes\n",
    "In this first version we're going to implement a recommendation system based on which animes the users have seen, for example if someone has watched cowboy bepop, they're going to be recommended to see death note\n",
    "#### Reducing the dataset\n",
    "As the dataset we're working with is too large, we're going to reduce it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['watched_episodes'], axis=1, inplace=True)\n",
    "dataset = dataset[(dataset['anime_id'] < 10000) & (dataset['user_id'] < 20000)]\n",
    "dataset = dataset[(dataset['user_id'] != 61960) & (dataset['watching_status'] != 4)]\n",
    "dataset = dataset.drop(\"watching_status\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see a sample of how the dataset is structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6702</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1</td>\n",
       "      <td>9253</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1</td>\n",
       "      <td>995</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1</td>\n",
       "      <td>4053</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1</td>\n",
       "      <td>2752</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  anime_id  rating\n",
       "0          0        67       9\n",
       "1          0      6702       7\n",
       "2          0       242      10\n",
       "3          0      4898       0\n",
       "4          0        21      10\n",
       "..       ...       ...     ...\n",
       "176        1      9253      10\n",
       "183        1        22       9\n",
       "184        1       995       8\n",
       "185        1      4053       9\n",
       "186        1      2752       8\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2509211"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(dataset.head(100))\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivot the dataset\n",
    "The next step is pivoting the dataset: we're constructing a matrix that will be used to build the recommendation system, where the rows are the users' ids and the columns are the animes' ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.pivot(index='user_id', columns='anime_id', values='rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now converting our matrix into a binary matrix in order to be able to retrieve the association rules: we only take into account the ratings that are above 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset > 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving the association rules\n",
    "Finally, we are exploiting the mlxtend library to build the recommendation system and we're retrieving the association rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets  = apriori(dataset, use_colnames=True, min_support=0.1) #Getting under 0.175 support takes too much computation time / memory.\n",
    "\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules[\"antecedents\"] = rules[\"antecedents\"].apply(lambda x: [x for x in x])\n",
    "rules[\"consequents\"] = rules[\"consequents\"].apply(lambda x: [x for x in x])\n",
    "rules = rules[rules[\"confidence\"] > 0.75]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some of the rules detected by the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[1]</td>\n",
       "      <td>[1535]</td>\n",
       "      <td>0.266154</td>\n",
       "      <td>0.591106</td>\n",
       "      <td>0.208125</td>\n",
       "      <td>0.781972</td>\n",
       "      <td>1.322896</td>\n",
       "      <td>0.050800</td>\n",
       "      <td>1.875418</td>\n",
       "      <td>0.332607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>[6]</td>\n",
       "      <td>[1535]</td>\n",
       "      <td>0.153170</td>\n",
       "      <td>0.591106</td>\n",
       "      <td>0.122317</td>\n",
       "      <td>0.798566</td>\n",
       "      <td>1.350969</td>\n",
       "      <td>0.031777</td>\n",
       "      <td>2.029917</td>\n",
       "      <td>0.306780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>[19]</td>\n",
       "      <td>[1535]</td>\n",
       "      <td>0.119956</td>\n",
       "      <td>0.591106</td>\n",
       "      <td>0.107384</td>\n",
       "      <td>0.895195</td>\n",
       "      <td>1.514439</td>\n",
       "      <td>0.036477</td>\n",
       "      <td>3.901454</td>\n",
       "      <td>0.385992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>[442]</td>\n",
       "      <td>[20]</td>\n",
       "      <td>0.109086</td>\n",
       "      <td>0.409113</td>\n",
       "      <td>0.100247</td>\n",
       "      <td>0.918973</td>\n",
       "      <td>2.246256</td>\n",
       "      <td>0.055619</td>\n",
       "      <td>7.292495</td>\n",
       "      <td>0.622748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>[20]</td>\n",
       "      <td>[1535]</td>\n",
       "      <td>0.409113</td>\n",
       "      <td>0.591106</td>\n",
       "      <td>0.321658</td>\n",
       "      <td>0.786232</td>\n",
       "      <td>1.330103</td>\n",
       "      <td>0.079829</td>\n",
       "      <td>1.912791</td>\n",
       "      <td>0.420010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69988</th>\n",
       "      <td>[4224, 9253, 2904, 5114, 1535]</td>\n",
       "      <td>[6547, 1575]</td>\n",
       "      <td>0.120999</td>\n",
       "      <td>0.276860</td>\n",
       "      <td>0.101839</td>\n",
       "      <td>0.841652</td>\n",
       "      <td>3.039993</td>\n",
       "      <td>0.068339</td>\n",
       "      <td>4.566765</td>\n",
       "      <td>0.763426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69991</th>\n",
       "      <td>[4224, 1575, 6547, 5114, 1535]</td>\n",
       "      <td>[2904, 9253]</td>\n",
       "      <td>0.130222</td>\n",
       "      <td>0.245622</td>\n",
       "      <td>0.101839</td>\n",
       "      <td>0.782040</td>\n",
       "      <td>3.183922</td>\n",
       "      <td>0.069854</td>\n",
       "      <td>3.461093</td>\n",
       "      <td>0.788618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69993</th>\n",
       "      <td>[4224, 6547, 2904, 5114, 1535]</td>\n",
       "      <td>[9253, 1575]</td>\n",
       "      <td>0.122591</td>\n",
       "      <td>0.268186</td>\n",
       "      <td>0.101839</td>\n",
       "      <td>0.830721</td>\n",
       "      <td>3.097561</td>\n",
       "      <td>0.068962</td>\n",
       "      <td>4.323126</td>\n",
       "      <td>0.771779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>[9253, 6547, 2904, 5114, 1535]</td>\n",
       "      <td>[4224, 1575]</td>\n",
       "      <td>0.134450</td>\n",
       "      <td>0.264233</td>\n",
       "      <td>0.101839</td>\n",
       "      <td>0.757452</td>\n",
       "      <td>2.866609</td>\n",
       "      <td>0.066313</td>\n",
       "      <td>3.033491</td>\n",
       "      <td>0.752303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70007</th>\n",
       "      <td>[4224, 5114, 2904, 9253]</td>\n",
       "      <td>[1535, 6547, 1575]</td>\n",
       "      <td>0.135383</td>\n",
       "      <td>0.230963</td>\n",
       "      <td>0.101839</td>\n",
       "      <td>0.752230</td>\n",
       "      <td>3.256923</td>\n",
       "      <td>0.070571</td>\n",
       "      <td>3.103836</td>\n",
       "      <td>0.801467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11386 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          antecedents         consequents  antecedent support  \\\n",
       "38                                [1]              [1535]            0.266154   \n",
       "84                                [6]              [1535]            0.153170   \n",
       "90                               [19]              [1535]            0.119956   \n",
       "120                             [442]                [20]            0.109086   \n",
       "138                              [20]              [1535]            0.409113   \n",
       "...                               ...                 ...                 ...   \n",
       "69988  [4224, 9253, 2904, 5114, 1535]        [6547, 1575]            0.120999   \n",
       "69991  [4224, 1575, 6547, 5114, 1535]        [2904, 9253]            0.130222   \n",
       "69993  [4224, 6547, 2904, 5114, 1535]        [9253, 1575]            0.122591   \n",
       "69998  [9253, 6547, 2904, 5114, 1535]        [4224, 1575]            0.134450   \n",
       "70007        [4224, 5114, 2904, 9253]  [1535, 6547, 1575]            0.135383   \n",
       "\n",
       "       consequent support   support  confidence      lift  leverage  \\\n",
       "38               0.591106  0.208125    0.781972  1.322896  0.050800   \n",
       "84               0.591106  0.122317    0.798566  1.350969  0.031777   \n",
       "90               0.591106  0.107384    0.895195  1.514439  0.036477   \n",
       "120              0.409113  0.100247    0.918973  2.246256  0.055619   \n",
       "138              0.591106  0.321658    0.786232  1.330103  0.079829   \n",
       "...                   ...       ...         ...       ...       ...   \n",
       "69988            0.276860  0.101839    0.841652  3.039993  0.068339   \n",
       "69991            0.245622  0.101839    0.782040  3.183922  0.069854   \n",
       "69993            0.268186  0.101839    0.830721  3.097561  0.068962   \n",
       "69998            0.264233  0.101839    0.757452  2.866609  0.066313   \n",
       "70007            0.230963  0.101839    0.752230  3.256923  0.070571   \n",
       "\n",
       "       conviction  zhangs_metric  \n",
       "38       1.875418       0.332607  \n",
       "84       2.029917       0.306780  \n",
       "90       3.901454       0.385992  \n",
       "120      7.292495       0.622748  \n",
       "138      1.912791       0.420010  \n",
       "...           ...            ...  \n",
       "69988    4.566765       0.763426  \n",
       "69991    3.461093       0.788618  \n",
       "69993    4.323126       0.771779  \n",
       "69998    3.033491       0.752303  \n",
       "70007    3.103836       0.801467  \n",
       "\n",
       "[11386 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing the rules\n",
    "These functions are designed to parse and filter the results of the detected rules, so we can understand them more easily.\n",
    "\n",
    "```find_recommendations_precise``` will compute every possible combination of the watched anime ids, and try to find them in the rules dataset.\n",
    "\n",
    "```find_recommendations_free``` will look for every occurence of each anime id in the rules, even if the antecedents frozen set isn't containing only the given id. (*__This needs improvement__*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "animes_df = pd.read_csv(path+\"anime.csv\")\n",
    "\n",
    "def generate_combinations(ids):\n",
    "\tresult = []\n",
    "\tfor r in range(1, len(ids) + 1):\n",
    "\t\tpermutations = itertools.permutations(ids, r)\n",
    "\t\tfor p in permutations:\n",
    "\t\t\tresult.append(list(p))\n",
    "\n",
    "\tprint(f\"Found {len(result)} possible combinations.\")\n",
    "\treturn result\n",
    "\n",
    "def find_recommendations_precise(anime_ids):\n",
    "\trecommendations = []\n",
    "\t\n",
    "\tfor combination in tqdm(generate_combinations(anime_ids), desc=\"Trying every possible combination...\"):\n",
    "\t\tfilter_df = rules[\"antecedents\"].apply(lambda x: x == combination) & rules[\"consequents\"].apply(lambda x: np.all([id not in x for id in anime_ids]))\n",
    "\t\tif filter_df.apply(lambda x: x != False).sum() < 1:\n",
    "\t\t\tcontinue\n",
    "\t\trecommendation = (combination, rules[filter_df][\"consequents\"].values, rules[filter_df][\"confidence\"].values, rules[filter_df][\"lift\"].values)\n",
    "\t\trecommendations.append(recommendation)\n",
    "\n",
    "\treturn recommendations\n",
    "\n",
    "def find_recommendations_free(anime_ids):\n",
    "\trecommendations = []\n",
    "\n",
    "\tfor id in anime_ids:\n",
    "\t\tfilter_df = rules[\"antecedents\"].apply(lambda x: id in x) & rules[\"consequents\"].apply(lambda x: np.all([id not in x for id in anime_ids]))\n",
    "\t\tif filter_df.apply(lambda x: x != False).sum() < 1:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\trecommendation = pd.DataFrame({\"source\": id, \"antecedents\": rules[filter_df][\"antecedents\"].values, \"consequents\": rules[filter_df][\"consequents\"].values, \"confidence\": rules[filter_df][\"confidence\"].values, \"lift\": rules[filter_df][\"lift\"].values})\n",
    "\t\trecommendations.append(recommendation)\n",
    "\n",
    "\trecommendations = pd.concat(recommendations)\n",
    "\n",
    "\treturn recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the previously defined function and parse the results to print them and link them with the anime infos dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_animes = [1, 6, 19, 20, 442] #More than 7 at a time takes forever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 325 possible combinations.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b8f637b25c491a859ad9ae543ffeed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Trying every possible combination...:   0%|          | 0/325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Because you have seen Cowboy Bebop (1), we think you would like Death Note (1535) with 78.197% confidence. You are also 32.290% more likely to watch this/these anime(s).\n",
      "Because you have seen Trigun (6), we think you would like Death Note (1535) with 79.857% confidence. You are also 35.097% more likely to watch this/these anime(s).\n",
      "Because you have seen Monster (19), we think you would like Death Note (1535) with 89.519% confidence. You are also 51.444% more likely to watch this/these anime(s).\n",
      "Because you have seen Naruto (20), we think you would like Death Note (1535) with 78.623% confidence. You are also 33.010% more likely to watch this/these anime(s).\n",
      "Because you have seen Cowboy Bebop (1) and Naruto (20), we think you would like Death Note (1535) with 87.515% confidence. You are also 48.052% more likely to watch this/these anime(s).\n",
      "Because you have seen Cowboy Bebop (1) and Naruto (20), we think you would like Fullmetal Alchemist: Brotherhood (5114) with 77.409% confidence. You are also 71.911% more likely to watch this/these anime(s).\n"
     ]
    }
   ],
   "source": [
    "for recommendations in find_recommendations_precise(seen_animes):\n",
    "\tfor i in range(len(recommendations[1])):\n",
    "\t\trecommendation = (recommendations[0], recommendations[1][i], recommendations[2][i], recommendations[3][i])\n",
    "\t\tprint(\"Because you have seen %s, we think you would like %s with %.3f%% confidence. You are also %.3f%% more likely to watch this/these anime(s).\" % (\n",
    "\t\t\t\" and \".join([animes_df[animes_df[\"MAL_ID\"] == x][\"Name\"].values[0] + f\" ({str(x)})\" for x in recommendation[0]]), \n",
    "\t\t\t\" and \".join([animes_df[animes_df[\"MAL_ID\"] == x][\"Name\"].values[0] + f\" ({str(x)})\" for x in recommendation[1]]), \n",
    "\t\t\trecommendation[2] * 100,\n",
    "\t\t\trecommendation[3] * 100 - 100)\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part needs improvement, because the results are not consise enough. \n",
    "# We could create a list of every anime that has been watch by people who's seen a certain anime, and return the most common ones instead of every one. \n",
    "for recommendations in find_recommendations_free(seen_animes):\n",
    "\tfor i in range(len(recommendations[1])):\n",
    "\t\trecommendation = (recommendations[0][i], recommendations[1][i], recommendations[2][i])\n",
    "\t\tprint(\"People who have seen %s, also liked watching %s with %.3f%% confidence.\" % (\n",
    "\t\t\t\" and \".join([animes_df[animes_df[\"MAL_ID\"] == x][\"Name\"].values[0] + f\" ({str(x)})\" for x in recommendation[0]]), \n",
    "\t\t\t\" and \".join([animes_df[animes_df[\"MAL_ID\"] == x][\"Name\"].values[0] + f\" ({str(x)})\" for x in recommendation[1]]), \n",
    "\t\t\trecommendation[2] * 100)\n",
    "\t\t)\n",
    "\t\tprint(\"************************************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1535]</td>\n",
       "      <td>0.781972</td>\n",
       "      <td>1.322896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 20]</td>\n",
       "      <td>[1535]</td>\n",
       "      <td>0.875146</td>\n",
       "      <td>1.480523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 20]</td>\n",
       "      <td>[5114]</td>\n",
       "      <td>0.774093</td>\n",
       "      <td>1.719105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[32, 1]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>0.982491</td>\n",
       "      <td>3.276470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 30]</td>\n",
       "      <td>[1535]</td>\n",
       "      <td>0.819661</td>\n",
       "      <td>1.386656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>20</td>\n",
       "      <td>[1535, 20, 9253, 1575]</td>\n",
       "      <td>[2904, 5114]</td>\n",
       "      <td>0.795661</td>\n",
       "      <td>2.980864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>20</td>\n",
       "      <td>[2904, 5114, 20, 9253]</td>\n",
       "      <td>[1535, 1575]</td>\n",
       "      <td>0.921425</td>\n",
       "      <td>2.584105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>20</td>\n",
       "      <td>[2904, 20, 9253, 1535]</td>\n",
       "      <td>[5114, 1575]</td>\n",
       "      <td>0.856476</td>\n",
       "      <td>2.923122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>20</td>\n",
       "      <td>[5114, 20, 9253, 1535]</td>\n",
       "      <td>[2904, 1575]</td>\n",
       "      <td>0.766920</td>\n",
       "      <td>2.018123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>20</td>\n",
       "      <td>[2904, 20, 9253]</td>\n",
       "      <td>[5114, 1535, 1575]</td>\n",
       "      <td>0.780573</td>\n",
       "      <td>3.082188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>721 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     source             antecedents         consequents  confidence      lift\n",
       "0         1                     [1]              [1535]    0.781972  1.322896\n",
       "1         1                 [1, 20]              [1535]    0.875146  1.480523\n",
       "2         1                 [1, 20]              [5114]    0.774093  1.719105\n",
       "3         1                 [32, 1]                [30]    0.982491  3.276470\n",
       "4         1                 [1, 30]              [1535]    0.819661  1.386656\n",
       "..      ...                     ...                 ...         ...       ...\n",
       "589      20  [1535, 20, 9253, 1575]        [2904, 5114]    0.795661  2.980864\n",
       "590      20  [2904, 5114, 20, 9253]        [1535, 1575]    0.921425  2.584105\n",
       "591      20  [2904, 20, 9253, 1535]        [5114, 1575]    0.856476  2.923122\n",
       "592      20  [5114, 20, 9253, 1535]        [2904, 1575]    0.766920  2.018123\n",
       "593      20        [2904, 20, 9253]  [5114, 1535, 1575]    0.780573  3.082188\n",
       "\n",
       "[721 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_recommendations_free(seen_animes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Graphs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
